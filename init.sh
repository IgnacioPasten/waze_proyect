#!/bin/bash

echo "ğŸ§¹ Limpiando contenedores y volÃºmenes antiguos..."
docker-compose down -v

echo "ğŸš€ Construyendo contenedores..."
docker-compose build

echo "ğŸ”„ Levantando servicios..."
docker-compose up -d

echo "â³ Esperando a que los servicios estÃ©n listos..."
sleep 30  # Esperar 30 segundos para que Hadoop se inicie completamente

echo "ğŸ˜ Configurando Hadoop HDFS..."
docker exec hadoop-pig bash -c "
  # Crear directorios en HDFS
  hdfs dfs -mkdir -p /user/root
  hdfs dfs -mkdir -p /user/waze

  # Copiar datos a HDFS si existen
  if [ -f '/data/incidentes_limpios.csv' ]; then
    hdfs dfs -put /data/incidentes_limpios.csv /user/waze/
    echo 'ğŸ“„ Archivo incidentes_limpios.csv copiado a HDFS'
  else
    echo 'âš ï¸  Advertencia: No se encontrÃ³ /data/incidentes_limpios.csv'
  fi

  # Dar permisos
  hdfs dfs -chmod -R 777 /user
  echo 'ğŸ”’ Permisos configurados en HDFS'

  # Verificar estructura
  echo 'ğŸ“‚ Estructura de HDFS:'
  hdfs dfs -ls -R /user
"

echo "âœ… Proyecto iniciado. Servicios corriendo:"
docker ps

echo "ğŸ”— URLs de acceso:"
echo " - Hadoop Namenode: http://localhost:50070"
echo " - YARN ResourceManager: http://localhost:8088"
echo " - MongoDB: mongodb://root:example@localhost:27017"